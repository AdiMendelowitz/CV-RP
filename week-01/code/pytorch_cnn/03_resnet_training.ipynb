{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-18 on CIFAR-10\n",
    "\n",
    "Training ResNet-18 from scratch on CIFAR-10 using a free Colab GPU.\n",
    "\n",
    "**Target: >85% test accuracy**\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "1. Go to **Runtime → Change runtime type → T4 GPU**\n",
    "2. Run all cells top to bottom\n",
    "3. Training takes ~15-20 minutes on T4 GPU\n",
    "4. Download results at the end\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('WARNING: No GPU found. Go to Runtime -> Change runtime type -> T4 GPU')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "# Clone repo\n",
    "!git clone https://github.com/AdiMendelowitz/CV-RP.git\n",
    "\n",
    "# Navigate to pytorch_cnn folder\n",
    "os.chdir('CV-RP/week-01/code/pytorch_cnn')\n",
    "print(f'Working directory: {os.getcwd()}')\n",
    "print(f'Files: {os.listdir()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Architecture Overview\n",
    "\n",
    "ResNet-18 uses **residual connections** (skip connections) to solve the vanishing gradient problem in deep networks:\n",
    "\n",
    "```\n",
    "output = F(x) + x\n",
    "```\n",
    "\n",
    "Instead of learning the full mapping, each block learns the **residual** — the difference from the identity. This allows gradients to flow directly through the network without degradation.\n",
    "\n",
    "```\n",
    "Input (3, 32, 32)\n",
    "    ↓\n",
    "Conv1 (3→64, 3×3)          # Smaller kernel than ImageNet version (7×7→3×3 for 32×32 input)\n",
    "BN + ReLU\n",
    "    ↓\n",
    "Layer1: 2× BasicBlock(64)   → (64, 32, 32)\n",
    "Layer2: 2× BasicBlock(128)  → (128, 16, 16)\n",
    "Layer3: 2× BasicBlock(256)  → (256, 8, 8)\n",
    "Layer4: 2× BasicBlock(512)  → (512, 4, 4)\n",
    "    ↓\n",
    "AvgPool → Flatten → Dense(512→10) → Softmax\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Import from repo\n",
    "from resnet import BasicBlock, ResNet, resnet18\n",
    "\n",
    "# Build model - adapted for CIFAR-10 (32x32 images, not 224x224)\n",
    "# Key difference from ImageNet ResNet-18:\n",
    "# - First conv: 3x3 instead of 7x7 (images are smaller)\n",
    "# - No maxpool after first conv (would reduce 32x32 too aggressively)\n",
    "class ResNet18CIFAR(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18 adapted for CIFAR-10.\n",
    "    \n",
    "    Changes from standard ImageNet ResNet-18:\n",
    "    - First conv: 7x7 stride 2 -> 3x3 stride 1 (preserve spatial resolution)\n",
    "    - Remove initial maxpool (32x32 is already small)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18CIFAR, self).__init__()\n",
    "        \n",
    "        self.current_channels = 64\n",
    "        \n",
    "        # CIFAR adaptation: smaller first conv, no maxpool\n",
    "        self.conv1   = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1     = nn.BatchNorm2d(64)\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        # No maxpool here (would destroy 32x32 spatial info)\n",
    "        \n",
    "        self.layer1  = self._make_layer(BasicBlock, 64,  2, stride=1)\n",
    "        self.layer2  = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3  = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4  = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc      = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = [block(self.current_channels, out_channels, stride)]\n",
    "        self.current_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  # (batch, 64, 32, 32)\n",
    "        x = self.layer1(x)                       # (batch, 64,  32, 32)\n",
    "        x = self.layer2(x)                       # (batch, 128, 16, 16)\n",
    "        x = self.layer3(x)                       # (batch, 256,  8,  8)\n",
    "        x = self.layer4(x)                       # (batch, 512,  4,  4)\n",
    "        x = self.avgpool(x)                      # (batch, 512,  1,  1)\n",
    "        x = torch.flatten(x, 1)                  # (batch, 512)\n",
    "        x = self.fc(x)                           # (batch, 10)\n",
    "        return x\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = ResNet18CIFAR(num_classes=10).to(device)\n",
    "print(f'Parameters: {model.count_parameters():,}')\n",
    "print(f'Device: {next(model.parameters()).device}')\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(4, 3, 32, 32).to(device)\n",
    "out = model(x)\n",
    "print(f'Input:  {x.shape}')\n",
    "print(f'Output: {out.shape}')\n",
    "assert out.shape == (4, 10)\n",
    "print('Forward pass OK!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Loading with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CIFAR-10 normalization values (computed from training set)\n",
    "MEAN = [0.4914, 0.4822, 0.4465]\n",
    "STD  = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "# Training transforms: augmentation + normalize\n",
    "# Augmentation is critical for generalization on CIFAR-10\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),       # Shift image randomly by up to 4px\n",
    "    transforms.RandomHorizontalFlip(p=0.5),     # Mirror 50% of images\n",
    "    transforms.ColorJitter(                     # Randomly adjust colors\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# Test transforms: only normalize, no augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# Download and load datasets\n",
    "print('Loading CIFAR-10...')\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True,  download=True, transform=train_transform\n",
    ")\n",
    "test_dataset  = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=128, shuffle=False,\n",
    "                          num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f'Train: {len(train_dataset):,} samples ({len(train_loader)} batches)')\n",
    "print(f'Test:  {len(test_dataset):,} samples ({len(test_loader)} batches)')\n",
    "\n",
    "CLASSES = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Reverse normalization for visualization.\"\"\"\n",
    "    mean = torch.tensor(MEAN).view(3, 1, 1)\n",
    "    std  = torch.tensor(STD).view(3, 1, 1)\n",
    "    return torch.clamp(tensor * std + mean, 0, 1)\n",
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = denormalize(images[i]).permute(1, 2, 0).numpy()\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(CLASSES[labels[i]], fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('CIFAR-10 Training Samples (with augmentation)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cifar10_samples.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved cifar10_samples.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'num_epochs':       50,\n",
    "    'learning_rate':    0.1,\n",
    "    'momentum':         0.9,\n",
    "    'weight_decay':     5e-4,\n",
    "    'lr_decay_epochs':  [20, 35, 45],   # Reduce LR by 10x at these epochs\n",
    "    'lr_decay_factor':  0.1,\n",
    "}\n",
    "\n",
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    momentum=CONFIG['momentum'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    ")\n",
    "\n",
    "# MultiStepLR reduces LR by factor at specified epochs\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=CONFIG['lr_decay_epochs'],\n",
    "    gamma=CONFIG['lr_decay_factor'],\n",
    ")\n",
    "\n",
    "print('Training configuration:')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss    = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total   += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs    = model(inputs)\n",
    "            loss       = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total   += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "# Training history\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [], 'lr': []}\n",
    "best_test_acc = 0.0\n",
    "total_start   = time.time()\n",
    "\n",
    "print('=' * 65)\n",
    "print(f'{\"Epoch\":<8} {\"Train Loss\":<12} {\"Train Acc\":<12} {\"Test Loss\":<12} {\"Test Acc\":<12} {\"LR\":<8}')\n",
    "print('=' * 65)\n",
    "\n",
    "for epoch in range(1, CONFIG['num_epochs'] + 1):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss,  test_acc  = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Save best model\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'best_resnet18_cifar10.pth')\n",
    "\n",
    "    # Log history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    target_hit = '✅' if test_acc >= 0.85 else ''\n",
    "\n",
    "    print(f'{epoch:<8} {train_loss:<12.4f} {train_acc:<12.4f} {test_loss:<12.4f} {test_acc:<12.4f} {current_lr:<8.4f} {epoch_time:.0f}s {target_hit}')\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print('=' * 65)\n",
    "print(f'Total time:    {total_time/60:.1f} minutes')\n",
    "print(f'Best test acc: {best_test_acc:.4f} ({best_test_acc*100:.2f}%)')\n",
    "print(f'Target >85%:   {\"✅ ACHIEVED\" if best_test_acc > 0.85 else \"❌ Not reached\"}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save History to JSON"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print('Saved training_history.json')\n",
    "print(f'Final Results:')\n",
    "print(f'  Train Acc: {history[\"train_acc\"][-1]:.4f}')\n",
    "print(f'  Test Acc:  {history[\"test_acc\"][-1]:.4f}')\n",
    "print(f'  Best Test: {best_test_acc:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "epochs = range(1, len(history['train_acc']) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs, history['train_loss'], label='Train Loss', color='steelblue')\n",
    "axes[0].plot(epochs, history['test_loss'],  label='Test Loss',  color='orange')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Over Time')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs, history['train_acc'], label='Train Accuracy', color='steelblue')\n",
    "axes[1].plot(epochs, history['test_acc'],  label='Test Accuracy',  color='orange')\n",
    "axes[1].axhline(y=0.85, color='red', linestyle='--', linewidth=1.5, label='85% target')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy Over Time')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "# Learning rate\n",
    "axes[2].plot(epochs, history['lr'], color='green', marker='o', markersize=3)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Learning Rate')\n",
    "axes[2].set_title('Learning Rate Schedule')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ResNet-18 on CIFAR-10 — Training Results', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('resnet_cifar10_training.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved resnet_cifar10_training.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load('best_resnet18_cifar10.pth'))\n",
    "model.eval()\n",
    "\n",
    "class_correct = [0] * 10\n",
    "class_total   = [0] * 10\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs        = model(inputs)\n",
    "        _, predicted   = torch.max(outputs, 1)\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i].item()\n",
    "            class_correct[label] += (predicted[i] == labels[i]).item()\n",
    "            class_total[label]   += 1\n",
    "\n",
    "class_acc = [class_correct[i] / class_total[i] for i in range(10)]\n",
    "\n",
    "# Print table\n",
    "print(f'Per-Class Accuracy (Best Model: {best_test_acc*100:.2f}%)')\n",
    "print('-' * 40)\n",
    "for i, (cls, acc) in enumerate(zip(CLASSES, class_acc)):\n",
    "    bar = '█' * int(acc * 25)\n",
    "    print(f'{cls:<8}: {acc:.4f}  {bar}')\n",
    "\n",
    "# Plot\n",
    "colors = ['#2ecc71' if acc >= 0.85 else '#e74c3c' for acc in class_acc]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "bars = plt.bar(CLASSES, class_acc, color=colors, edgecolor='black', linewidth=0.5)\n",
    "plt.axhline(y=0.85, color='red', linestyle='--', linewidth=1.5, label='85% target')\n",
    "plt.axhline(y=best_test_acc, color='blue', linestyle=':', linewidth=1.5, label=f'Overall ({best_test_acc*100:.1f}%)')\n",
    "\n",
    "for bar, acc in zip(bars, class_acc):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "             f'{acc:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.title('ResNet-18 Per-Class Accuracy on CIFAR-10', fontsize=13)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('resnet_per_class.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved resnet_per_class.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images_gpu = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs     = model(images_gpu)\n",
    "    probs       = torch.softmax(outputs, dim=1)\n",
    "    confidences, predictions = torch.max(probs, 1)\n",
    "\n",
    "# Show first 16 samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 5))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img        = denormalize(images[i]).permute(1, 2, 0).numpy()\n",
    "    true_label = CLASSES[labels[i]]\n",
    "    pred_label = CLASSES[predictions[i].item()]\n",
    "    confidence = confidences[i].item()\n",
    "    correct    = labels[i] == predictions[i].cpu()\n",
    "\n",
    "    ax.imshow(img)\n",
    "    color = 'green' if correct else 'red'\n",
    "    ax.set_title(f'{pred_label}\\n({confidence:.0%})', fontsize=8, color=color)\n",
    "    ax.set_xlabel(f'True: {true_label}', fontsize=7)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(color)\n",
    "        spine.set_linewidth(2)\n",
    "\n",
    "plt.suptitle('Predictions (green=correct, red=wrong)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('resnet_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved resnet_predictions.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('=' * 55)\n",
    "print('FINAL RESULTS — ResNet-18 on CIFAR-10')\n",
    "print('=' * 55)\n",
    "print(f'  Best Test Accuracy:   {best_test_acc*100:.2f}%')\n",
    "print(f'  Final Train Accuracy: {history[\"train_acc\"][-1]*100:.2f}%')\n",
    "print(f'  Final Test Accuracy:  {history[\"test_acc\"][-1]*100:.2f}%')\n",
    "print(f'  Total Epochs:         {CONFIG[\"num_epochs\"]}')\n",
    "print(f'  Training Time:        {total_time/60:.1f} minutes')\n",
    "print(f'  Device:               {device}')\n",
    "print(f'  Parameters:           {model.count_parameters():,}')\n",
    "print()\n",
    "print(f'  Target >85%:          {\"✅ ACHIEVED\" if best_test_acc > 0.85 else \"❌ Not reached\"}')\n",
    "print()\n",
    "print('Benchmark comparison:')\n",
    "print(f'  Random guessing:      10.00%')\n",
    "print(f'  This model (50ep):    {best_test_acc*100:.2f}%')\n",
    "print(f'  Paper (100ep, GPU):   ~93.00%')\n",
    "print(f'  State of the art:     ~99.00%')\n",
    "print('=' * 55)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import files\n",
    "\n",
    "print('Downloading files...')\n",
    "\n",
    "# Model weights\n",
    "files.download('best_resnet18_cifar10.pth')\n",
    "\n",
    "# Training history\n",
    "files.download('training_history.json')\n",
    "\n",
    "# Plots\n",
    "files.download('resnet_cifar10_training.png')\n",
    "files.download('resnet_per_class.png')\n",
    "files.download('resnet_predictions.png')\n",
    "files.download('cifar10_samples.png')\n",
    "\n",
    "print('All files downloaded!')\n",
    "print()\n",
    "print('Next steps:')\n",
    "print('  1. Move .png files to week-01/code/pytorch_cnn/outputs/')\n",
    "print('  2. Move .pth and .json to week-01/code/pytorch_cnn/')\n",
    "print('  3. git add . && git commit -m \"ResNet-18 CIFAR-10 results\" && git push')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
